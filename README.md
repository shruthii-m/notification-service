# The goal of my thinking as a completion creteria for the project is outlined below.
* This is how the outcome of this project should be looking like.
* I will be updating this project incrementally.


# Notification Service – Design Document

## 1. Overview

The **Notification Service** is a multi-tenant, event-driven microservice responsible for processing and delivering notifications (Email, SMS, Push) for multiple organizations.

It is designed to be:

* **Scalable**
* **Fault-tolerant**
* **Auditable**
* **Kafka-driven**
* **Multi-tenant (organization-based isolation)**

---

## 2. High-Level Goals

* Allow **any organization** to publish notification requests to Kafka
* Process notifications asynchronously
* Guarantee **at-least-once delivery**
* Prevent duplicate notifications (idempotency)
* Store full **audit history**
* Allow organizations to **query their notification data**
* Support retries and dead-letter handling

---

## 3. Architecture Overview

### Event Flow

```
User / Upstream Service
        |
        | (notification.requested)
        v
Kafka Topic
        |
        v
Notification Service
  - Persist notification (PENDING)
  - Validate & deduplicate
  - Publish send task
        |
        v
Kafka (notification.send)
        |
        v
Sender Worker
  - Send via provider
  - Retry on transient failure
  - Update status (SENT / FAILED)
  - Publish status event

```

---

## 4. Kafka Design

### Topics

| Topic Name                | Purpose                         |
| ------------------------- | ------------------------------- |
| `notification.requested`  | Incoming notification requests  |
| `notification.send`       | Tasks for sending notifications |
| `notification.send.retry` | Retry attempts                  |
| `notification.send.dlt`   | Permanent failures              |
| `notification.status`     | Status updates                  |

---

### Partitioning Strategy

* **Kafka key**: `organizationId`
* Ensures:

  * All notifications for an organization go to the same partition
  * Ordering is preserved per organization

```text
partition = hash(organizationId) % numPartitions
```

// note: For start, I will just hash orgId and not mod by partition.

---

### Kafka Message Contract (Example)

```json
{
  "notificationId": "uuid",
  "organizationId": "uuid",
  "eventType": "USER_REGISTERED",
  "channel": "EMAIL",
  "recipient": "user@example.com",
  "payload": {
    "name": "John",
    "link": "https://example.com"
    ...
  },
  "createdAt": "2025-01-01T10:00:00Z"
}
```

---

## 5. Idempotency Strategy

Kafka provides **at-least-once delivery**, so deduplication is required.

* `notificationId` is generated by the producer
* Stored as **PRIMARY KEY** in DB
* Duplicate events are safely ignored at DB level

---

## 6. Database Design (PostgreSQL)

### Enums

```sql
CREATE TYPE notification_status AS ENUM (
  'PENDING',
  'PROCESSING',
  'SENT',
  'FAILED',
  'RETRYING'
);

CREATE TYPE notification_channel AS ENUM (
  'EMAIL',
  'SMS',
  'PUSH'
);
```

---

### Primary Table: `notifications`

```sql
CREATE TABLE notifications (
    id UUID PRIMARY KEY DEFAULT random_uuid() or inc_id(),
    organization_id UUID NOT NULL,

    event_type VARCHAR(100) NOT NULL,
    channel notification_channel NOT NULL,
    recipient VARCHAR(255) NOT NULL,

    payload JSONB NOT NULL,
    status notification_status NOT NULL,

    provider VARCHAR(50),
    provider_message_id VARCHAR(255),

    retry_count INT DEFAULT 0,
    max_retries INT DEFAULT 5,

    error_code VARCHAR(100),
    error_message TEXT,

    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    sent_at TIMESTAMP
);
```

---

### Indexing Strategy

```sql
-- Org-based queries
CREATE INDEX idx_notifications_org_created
ON notifications (organization_id, created_at DESC);

-- Status queries
CREATE INDEX idx_notifications_org_status
ON notifications (organization_id, status);

-- Retry worker optimization
CREATE INDEX idx_notifications_retry
ON notifications (status, retry_count)
WHERE status IN ('FAILED', 'RETRYING');
```

---

## 7. Audit Table: `notification_events`

Stores full lifecycle history of each notification.

```sql
CREATE TABLE notification_events (
    id BIGSERIAL PRIMARY KEY,
    notification_id UUID NOT NULL,
    organization_id UUID NOT NULL,

    event VARCHAR(50) NOT NULL, -- CREATED, SEND_ATTEMPT, SENT, FAILED, RETRIED
    details JSONB,

    created_at TIMESTAMP NOT NULL DEFAULT NOW(),

    CONSTRAINT fk_notification
        FOREIGN KEY (notification_id)
        REFERENCES notifications(id)
        ON DELETE CASCADE
);
```

### Indexes

```sql
CREATE INDEX idx_events_notification
ON notification_events (notification_id);

CREATE INDEX idx_events_org_created
ON notification_events (organization_id, created_at DESC);
```

---

## 8. Notification State Machine

```
PENDING
   ↓
PROCESSING
   ↓
SENT
   ↓
FAILED → RETRYING → SENT
            ↓
           DLT
```

---

## 9. Retry & Failure Handling

* Retry up to `max_retries`
* Transient failures → `notification.send.retry`
* Permanent failures → `notification.send.dlt`
* All failures recorded in audit table

---

## 10. Multi-Tenancy & Security

* `organizationId` is mandatory in:

  * Kafka message
  * Database schema
* Organization context must come from:

  * Kafka headers
  * API gateway
  * Auth token (JWT)

// note: Planning to add security at the last

All queries MUST include:

```sql
WHERE organization_id = :orgId
```

---

## 11. Observability

* Correlation ID = `notificationId`
* Structured logging
* Metrics:

  * Send success rate
  * Retry count
  * Processing latency

---

## 12. Extensibility

Designed to easily add:

* New channels (WhatsApp, Slack)
* Multiple providers per channel
* Template management
* Rate limiting per organization
* DB partitioning by `organization_id`

---

## 13. Design Principles

## Software Design Patterns Used

This service intentionally applies the following **software design patterns** to ensure scalability, maintainability, and reliability.

---

### Event-Driven Architecture (EDA)
Used to decouple notification producers from consumers using Kafka. Enables asynchronous processing, scalability, and fault isolation.

---

### Producer–Consumer Pattern
Kafka producers publish notification events, and Kafka consumers process them independently, allowing parallelism and back-pressure handling.

---

### Strategy Pattern
Applied to notification sending logic to support multiple channels and providers (Email, SMS, Push) without conditional branching.

---

### Factory Pattern
Used to create appropriate notification sender implementations based on channel and provider at runtime.

---

### State Pattern
Models the notification lifecycle (PENDING, PROCESSING, SENT, FAILED, RETRYING) and enforces valid state transitions.

---

### Idempotent Consumer Pattern
Ensures duplicate Kafka messages do not result in duplicate notifications by using `notificationId` as a unique key.

---

### Retry Pattern
Handles transient failures by retrying notification delivery with controlled retry limits and backoff.

---

### Dead Letter Queue (DLQ) Pattern
Routes permanently failed notification messages to a dedicated topic for inspection and manual intervention.

---

### Repository Pattern
Abstracts database access logic, keeping domain logic independent of persistence concerns.

---

### Single Responsibility Principle (SRP)
Each component (consumer, sender, retry handler, persistence layer) has a single, well-defined responsibility.

---

## 15. Conclusion

This design provides a **scalable, auditable, and production-ready** notification platform suitable for multi-tenant systems.

This document serves as the **single source of truth** for:

* Architecture decisions
* Data modeling
* Kafka strategy
* Future evolution

---